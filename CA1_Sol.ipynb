{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer 1 Start\n",
    "#---------------------------------------------------------------\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images.shape\n",
    "plt.imshow(train_images[200], cmap='binary')\n",
    "\n",
    "#generate a list [0,1,2,....9]\n",
    "output_labels = list(sorted(set(train_labels)))\n",
    "\n",
    "# normalize the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# plot sample data\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(train_images[i], cmap='binary')\n",
    "    plt.xlabel(train_labels[i])\n",
    "    \n",
    "#build the model\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              #loss='mean_squared_error',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "# Answer 1 Ends\n",
    "#---------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 2 Start\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "#2.a start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(4, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              #loss='mean_squared_error',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "# It can be seen that increasing the number of nodes in the hidden layer\n",
    "# increases the test accuracy but also increases the time taken to train the mode.\n",
    "# For nodes=4, accuracy is about 85% and time taken about 6s ; for nodes > 128,\n",
    "# accuracy saturates to about 98%. Increasing nodes to more than 128 doesn't have \n",
    "# much impact on accuracy, although the time taken to train increases\n",
    "# considerably (from 15s for n=128 to 84s for n=1024)\n",
    "\n",
    "# 2.a End------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.b start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(1, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              #loss='mean_squared_error',\n",
    "              #loss='categorical_hinge',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "#It is conceivable that using different loss functions \n",
    "# provide different accuracy levels and the time will also vary \n",
    "# based on the problem at hand (recognizing digits in this case).\n",
    "# Each loss function is suited to a certain category of neural nets.\n",
    "# Using different loss functions means the output layer of the network needs to \n",
    "# be changed. \n",
    "#2.b End-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.c start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(#optimizer='adam',\n",
    "             #optimizer='sgd',\n",
    "            #optimizer='nadam',\n",
    "              optimizer='adadelta',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              #loss='mean_squared_error',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "\n",
    "#For n=128 hidden layer, 'nadam' (98%), 'adam'(97%) and 'adadelta'(97%) provide much better accuracy\n",
    "# than 'sgd'(90%) optimizer\n",
    "#2.c end-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.e start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=1)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "# For n=128 hidden layer, the accuracy improves from 92% (epochs=1)\n",
    "# 99% (epochs=10). The 99% accuracy could mean we are over fitting the \n",
    "# model though.\n",
    "#2.e end-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.f start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3, batch_size=4086)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "\n",
    "# A higher batch size decreases the time to train the network,\n",
    "# though the accuracy is lower.\n",
    "# for example, batch_size=8 (time=65s, accuracy=97%);\n",
    "# batch_size=4096 (time=4s, accuracy=87%)\n",
    "#2.f end-------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.g start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "\n",
    "# Adding an extra hidden layer n=128 doesn't seem to have much\n",
    "# effect on neither the accuracy nor the time taken.\n",
    "#2.g end-------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.h start-------------------------------------------\n",
    "model=keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=train_images[i].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "#run the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_loss, test_acc\n",
    "\n",
    "# Adding 2 exra hidden layers doesn't seem to have much effect on the\n",
    "# time taken nor the accuracy of the network\n",
    "#2.h end-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Start-------------------------------------------\n",
    "#Prepare to read the student number\n",
    "image = Image.open(\"std_num.JPG\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(left=(0, image.size[0]-2), top=(0, image.size[1]-2), right=(0,image.size[0]-2),\n",
    "          bottom=(0, image.size[1]-2))\n",
    "def cropImage(fileName=\"cropped.png\", left=0, top=0, right=image.size[0], bottom=image.size[1]):\n",
    "    croppedImage = image.crop([left, top, right, bottom])\n",
    "    plt.close()\n",
    "    plt.imshow(croppedImage)\n",
    "    croppedImage.save(fileName)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = Image.open(\"cropped.png\").resize((28,28))\n",
    "plt.imshow(digit)\n",
    "# convert to greyscale\n",
    "digit = np.array(digit.convert(\"L\"))\n",
    "#plt.imshow(digit, cmap=\"binary\")\n",
    "\n",
    "# scale to values between 0 and 1\n",
    "digit = (np.max(digit) - digit) / (np.max(digit) - np.min(digit))\n",
    "plt.imshow(digit, cmap=\"binary\")\n",
    "\n",
    "digit[digit<0.4] = 0\n",
    "plt.imshow(digit, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the digit in the student number\n",
    "predict_array = model.predict(np.reshape(digit, (1,digit.shape[0], digit.shape[1])),\n",
    "                    verbose=1)\n",
    "predict_array\n",
    "print(\"Digit recognized = \", output_labels[np.argmax(predict_array)])\n",
    "#print(\"Digit recognized = \", np.argmax(predict_array))\n",
    "predict_array\n",
    "\n",
    "# It looks like the model is having difficulty recognizing the digits in \n",
    "# the student number. This is most prabably because of the coarse \n",
    "# image formatting method performed here. With suitably sophsticated\n",
    "# image manipulation algorithm which formats the student number image into \n",
    "# a proper format, the method should work well.\n",
    "#3 end-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
